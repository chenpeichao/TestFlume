#\u5c06\u91c7\u96c6\u7684\u6570\u636e\u4fdd\u5b58\u5230hdfs\u4e2d
#\u5b9a\u4e49agent\u540d\uff0c source\u3001channel\u3001sink\u7684\u540d\u79f0
a1.sources = r1
a1.sinks = k1
a1.channels = c1


#\u5b9a\u4e49source
a1.sources.r1.type = avro
a1.sources.r1.bind = hadoop01
a1.sources.r1.port =4141

#\u6dfb\u52a0\u65f6\u95f4\u62e6\u622a\u5668
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = org.apache.flume.interceptor.TimestampInterceptor$Builder


#\u5b9a\u4e49channels
a1.channels.c1.type = memory
a1.channels.c1.capacity = 20000
a1.channels.c1.transactionCapacity = 10000

#\u5b9a\u4e49sink
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path=hdfs://hadoop01:9000/flow_project/logs/%{hostname}/%{type}/%Y%m%d
a1.sinks.k1.hdfs.filePrefix =events
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.writeFormat = Text
#\u65f6\u95f4\u7c7b\u578b
#a1.sinks.k1.hdfs.useLocalTimeStamp = true
#\u751f\u6210\u7684\u6587\u4ef6\u4e0d\u6309\u6761\u6570\u751f\u6210
a1.sinks.k1.hdfs.rollCount = 0
#\u751f\u6210\u7684\u6587\u4ef6\u4e0d\u6309\u65f6\u95f4\u751f\u6210
a1.sinks.k1.hdfs.rollInterval = 30
#\u751f\u6210\u7684\u6587\u4ef6\u6309\u5927\u5c0f\u751f\u6210
a1.sinks.k1.hdfs.rollSize  = 10485760
#a1.sinks.k1.hdfs.rollSize  =0
#\u6279\u91cf\u5199\u5165hdfs\u7684\u4e2a\u6570
a1.sinks.k1.hdfs.batchSize = 10000
flume\u64cd\u4f5chdfs\u7684\u7ebf\u7a0b\u6570\uff08\u5305\u62ec\u65b0\u5efa\uff0c\u5199\u5165\u7b49\uff09
a1.sinks.k1.hdfs.threadsPoolSize=10
#\u64cd\u4f5chdfs\u8d85\u65f6\u65f6\u95f4
a1.sinks.k1.hdfs.callTimeout=30000

#\u7ec4\u88c5source\u3001channel\u3001sink
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
